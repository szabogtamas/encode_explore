---
title: "`r params$report_title`"
author: "`r params$report_author`"
date: "`r params$report_time`"
output:
  html_document:
    toc: True
params:
  report_title: "Demonstrate RCAS capabilities on ENCODE data"
  report_author: "Anonymus"
  report_time: !r format(Sys.Date(), format="%d/%m/%Y")
  genome_annotation: "s3://encode-public/2019/06/04/8f6cba12-2ebe-4bec-a15d-53f498979de0/gencode.v29.primary_assembly.annotation_UCSC_names.gtf.gz"
  encode_files_manifest_s3: "s3://encode-public/encode_file_manifest.tsv"
  encode_local_manifest: "encode_s3_manifest.tsv"
  experiments_of_interest: ["ENCSR767LLP"]
  chromosome: "chr9"
  genomic_range: [94178791, 94178963]
---

## Setup

```{r}
library(dplyr)
library(tidyr)
library(purrr)
library(RCAS)
library(GenomicRanges)
library(GenomicFeatures)
```

## Download S3 repo contents

```{r}
system(
  paste(
    "aws s3 cp", params$encode_files_manifest_s3, params$encode_local_manifest,
    "--no-sign-request", sep=" "
  ),
  intern=FALSE
)

manifests <- read.csv(params$encode_local_manifest, sep="\t")
head(manifests)
```

## Show files associated with experiment

```{r}
samples_df <- manifests %>%
  dplyr::filter(dataset %in% paste0("/experiments/", params$experiments_of_interest, "/")) %>%
  dplyr::filter(file_format == "bam") %>%
  dplyr::filter(output_type == "transcriptome alignments") %>%
  dplyr::filter(analysis_step_version.analysis_step.name == "bulk-rna-seq-alignment-step-v-1") %>%
  dplyr::filter(assembly == "GRCh38") %>%
  dplyr::select(accession, dataset, s3_uri) %>%
  mutate(dataset = gsub("/experiments/", "", dataset)) %>%
  mutate(dataset = gsub("/", "", dataset))

samples_df
```

## Download bam files from ENCODE

```{r}
retrieve_bed_files <- function(accession, dataset, s3_uri) {
  local_path <- paste(accession, "bam", sep=".")
  local_bed_path <- paste(accession, "bed", sep=".")
  #system(paste("aws s3 cp", s3_uri, local_path, "--no-sign-request", sep=" "), intern=FALSE)
  #system(paste("bedtools bamtobed -i", local_path, ">", local_bed_path, sep=" "), intern=FALSE)
  data.frame(accession=accession, dataset=dataset, s3_uri=s3_uri, local_bed_path)
}

local_samples_df <- samples_df %>%
  pmap(retrieve_bed_files) %>%
  bind_rows()

local_samples_df
```

## Parse genome annotation

```{r}
remove_gtf <- FALSE
genome_annotation_gtf <- params$genome_annotation
if (substr(params$genome_annotation, 1, 5) == "s3://") {
  genome_annotation_gtf <- "tmp_gtf.gtf.gz"
  remove_gtf <- TRUE
}
```

```{r}
base_gff <- importGtf(genome_annotation_gtf)
gtf_genome <- makeTxDbFromGFF(genome_annotation_gtf)
if (remove_gtf) unlink(genome_annotation_gtf)
transcriptCoords <- transcripts(gtf_genome)
```

## Feature Boundary Coverage Profiles

```{r}
sample_1_bed <- importBed(filePath="ENCFF465VPI.bed", sampleN=5000)
sample_2_bed <- importBed(filePath="ENCFF683UDV.bed", sampleN=5000)
```

```{r}
cvgF <- getFeatureBoundaryCoverage(
  queryRegions = sample_1_bed,
  featureCoords = transcriptCoords,
  flankSize = 500,
  boundaryType = 'fiveprime',
  sampleN = 1000
)
```
```{r}
cvgT <- getFeatureBoundaryCoverage(
  queryRegions = sample_1_bed,
  featureCoords = transcriptCoords,
  flankSize = 500,
  boundaryType = 'threeprime',
  sampleN = 1000
)
```

```{r}
plotFeatureBoundaryCoverage(cvgF = cvgF, cvgT = cvgT, featureName = 'transcript') 
```
